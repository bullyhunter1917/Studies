{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bullyhunter1917/Studies/blob/main/NN-and-NLP/NN_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-caefeb56-f9c5-4f9e-a096-b89246dc63d7",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 6
        },
        "deepnote_cell_type": "markdown",
        "id": "CGXgWugfJ0Vl"
      },
      "source": [
        "## Assignment 1\n",
        "\n",
        "**Submission deadlines:** \n",
        "- get at least **2** points by Tuesday, 07.03.2023\n",
        "- remaining points: last lab session before or on Thursday, 16.03.2023\n",
        "\n",
        "**Points:** Aim to get 8 out of 12 possible points\n",
        "\n",
        "## Submission instructions\n",
        "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\n",
        "Make sure you know all the questions and asnwers, and that the notebook contains results; bfore presentation do `Runtime -> Restart and run all`\n",
        "![Picture title](image-20220302-183151.png)\n",
        "\n",
        "We provide starter code, however you are not required to use it as long as you properly solve the tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00002-c92cc86e-f65f-4e16-9124-9ca4d4265c88",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 12
        },
        "deepnote_cell_type": "markdown",
        "id": "5S8iRaCPyO2a"
      },
      "source": [
        "# Task description\n",
        "\n",
        "## TLDR\n",
        "Implement and train a neural network using pure numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00003-1893a0a0-4515-4960-bce8-37f660543eea",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 18
        },
        "deepnote_cell_type": "markdown",
        "id": "JHcz7I2V-bVM"
      },
      "source": [
        "\n",
        "## Problem 1 [2p]\n",
        "Implement a two-layer network, manually set weights and biases to solve the XOR task.\n",
        "\n",
        "A two-layer neural network implementes a function $f: \\mathbb{R}^D \\rightarrow \\mathbb{R}^O$ where $D$ is the input dimensionality and $O$ is the output dinemsionality. The output goes through an intermediate representation (the hidden layer) with dimensionality $H$. \n",
        "\n",
        "The computations are as follows:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A_1 &= x W_1^T + b_1  & \\qquad\\text{Total input to neurons in the hidden layer (network's first layer)} \\\\\n",
        "O_1 &= \\sigma_1(A_1)  & \\qquad\\text{Output of the hidden layer} \\\\\n",
        "A_2 &= O_1 W_2^T + b_2 & \\qquad\\text{Total input to neurons in the output layer (network's second layer)}\\\\\n",
        "O_2 &= \\sigma_2(A_2)  & \\qquad\\text{Output of the network}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Where $W$ are weight matrices, $b$ are bias vectors, $\\sigma$ are non-linear activation functions (e.g. the logistic sigmoid applied element-wise, or softmax).\n",
        "\n",
        "For the 2D xor problem the network will:\n",
        "- have 2 inputs, 2 hidden neurons, one output\n",
        "- use the logistic sigmoid everywhere (that way we, when hand-designig the weights, we can assume that neurons' outputs are binary).\n",
        "\n",
        "Therrefore the shapes of the data flowing through the network will be:\n",
        "- input: $x\\in\\mathbb{}R^{2}$\n",
        "- hidden layer parameters: $W_1\\in\\mathbb{}R^{2\\times 2}$ and $b_1\\in\\mathbb{}R^{2}$\n",
        "- representations in the hidden layer: $A_1\\in\\mathbb{}R^{2}$ and $O_1\\in\\mathbb{}R^{2}$\n",
        "- output layer parameters: $W_2\\in\\mathbb{}R^{1\\times 2}$ and $b_2\\in\\mathbb{}R^{1}$\n",
        "- representations in the output layer: $A_2\\in\\mathbb{}R^{1}$ and $O_2\\in\\mathbb{}R^{1}$\n",
        "\n",
        "The network can be seen as a logistic regression model, prefixed by a nonlinear transformation of the data.\n",
        "\n",
        "The first tasks consists of:\n",
        "- implementing the network\n",
        "- selecting parametwrs ($W_1, b_1, W_2, b_2$) such that $f(x)\\approx XOR(x_1, x_2)$ where the approximation is die to the sigmoids - the output may be close to 0 or 1, but doesn't need to saturate at 0 or 1.\n",
        "\n",
        "NB: the convention on weight matrix shapes follows linear [layers in PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-0d502510-cfd1-44da-b88c-da6aaf275617",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 24
        },
        "deepnote_cell_type": "markdown",
        "id": "0QSpZxuH-bLe"
      },
      "source": [
        "## Problem 2 [2p]\n",
        "1. Add a backward pass.\n",
        "2. Use a sensible random initialization for weights and biases.\n",
        "3. Numerically check the correctness of your gradient computation.\n",
        "\n",
        "There is nice article about taking derivative over vectors and vector chain rule: https://explained.ai/matrix-calculus/ if someone don't have experience with suchr calculus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00005-96083315-f850-4103-946e-cc9b11377543",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 30
        },
        "deepnote_cell_type": "markdown",
        "id": "s1Tn8j0m-bAy"
      },
      "source": [
        "## Problem 3 [2p]\n",
        "1. Implement gradient descent\n",
        "2. Train your network to solve 3D XOR\n",
        "3. Try several hidden layer sizes, for each size record the fracton of successful trainings. Then answer:\n",
        "    - What is the minimal hidden size required to solve 3D XOR (even with low reliability, when the training has to be repeated multiple times)\n",
        "    - What is the minimal hidden size required to reliably solve 3D XOR\n",
        "    - Which networks are easier to train - small or large ones? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00006-94cc4eb9-0202-4308-9a9e-007db44a6a98",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 36
        },
        "deepnote_cell_type": "markdown",
        "id": "RP9Pvpmf-a2A"
      },
      "source": [
        "## Problem 4 [1p]\n",
        "Replace the first nonlinearity with the [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) activation function. Find a network architecture which reliably learns the 3D XOR problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00007-9e6e984c-5131-4333-837b-7e57c4bfb650",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 42
        },
        "deepnote_cell_type": "markdown",
        "id": "cGgtpe-w-asB"
      },
      "source": [
        "## Problem 5 [1p]\n",
        "Add a second hidden layer to your network, implement the forward and backward pass, then demonstrate training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00008-86ea4bdd-83dc-4197-baad-d216fbacc786",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 48
        },
        "deepnote_cell_type": "markdown",
        "id": "Pe-pcFeO-aiE"
      },
      "source": [
        "## Problem 6 [2p]\n",
        "Implement a way to have a _variable number_ of hidden layers. Check how deep sigmoid or ReLU networks you  can train. For simplicity you can assume that all hidden layers have the same number of neurons, and use the same activation function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00009-64a0b978-7933-40be-89e4-a3d35d52c7ab",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 54
        },
        "deepnote_cell_type": "markdown",
        "id": "kIpn17Cm-aW7"
      },
      "source": [
        "## Problem 7 [2p]\n",
        "For each weight matrix $w\\in\\mathbb{R}^{n\\times m}$, add a randomly initialized `backward weight` $w_b\\in\\mathbb{R}^{m\\times n}$, which will not change during training. Change the backward pass to use $w_b$ instead of $w^T$, getting an approxmatoin of the true gradient. Can you get your network to train?\n",
        "\n",
        "NB: this approach, dubbed [feedback alignment](https://www.nature.com/articles/ncomms13276), was proposed to make error backpropagation more biologically plausible, by providing a solution to the \"weight transport problem\". Regular backpropagation requires that neurons not only know their incoming weights (thet they control), but also their outgoing weights (that are controlled by neurons in the upper layers). This is nearly impossible in a real brain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00010-954fd65b-4d81-4bbc-bf6b-4d10d50be9b8",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 60
        },
        "deepnote_cell_type": "markdown",
        "id": "rXJaoHSH0DZO"
      },
      "source": [
        "# Solutions and starter code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00011-97f2c7fe-a3d5-4a6b-bc12-8a96bfeed475",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 66
        },
        "deepnote_cell_type": "code",
        "id": "YiTEWD2oqW0Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00012-8bc44e88-e665-483d-89fc-c866879ad335",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 72
        },
        "deepnote_cell_type": "markdown",
        "id": "eqtfJKR40J3x"
      },
      "source": [
        "XOR dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00013-3adfc55c-5dcc-476a-9e4a-328f2044ebc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 78
        },
        "deepnote_cell_type": "code",
        "id": "lYEbCfbSpv5M",
        "outputId": "d34b50d2-ca00-48b7-afb5-db52f8f44981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.05, 1.05, -0.05, 1.05)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Let's define a XOR dataset\n",
        "\n",
        "# X will be matrix of N 2-dimensional inputs\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1],], dtype=np.float32)\n",
        "# Y is a matrix of N numners - answers\n",
        "Y = np.array([[0], [1], [1], [0],], dtype=np.float32)\n",
        "\n",
        "plt.scatter(\n",
        "    X[:, 0], X[:, 1], c=Y[:, 0],\n",
        ")\n",
        "plt.xlabel(\"X[0]\")\n",
        "plt.ylabel(\"X[1]\")\n",
        "plt.axis(\"square\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00014-fe501b87-4247-497d-a7c7-f528483d31cc",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 84
        },
        "deepnote_cell_type": "markdown",
        "id": "Rb3azMn929_I"
      },
      "source": [
        "## Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00015-97a3483d-0ae6-4bee-afd5-6226abc622a5",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 90
        },
        "deepnote_cell_type": "markdown",
        "id": "RZCM_hdELE04"
      },
      "source": [
        "The code below contains a mock-up of a two-layer neural network. Fill in the code and manually set weights to solve the XOR problem.\n",
        "\n",
        "Please note: the shapes are set to be compatible with PyTorch's conventions:\n",
        "* a batch containing $N$ $D$-dimensional examples has shape $N\\times D$ (each example is a row!)\n",
        "* a weight matrix in a linear layer with $I$ inputs and $O$ outputs has shape $O \\times I$\n",
        "* a bias vector is a 1D vector. Please note that [broadcasting rules](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) allow us to think about it as a $1 \\times D$ matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00016-87dd53c6-4f21-4286-8a85-61c2a92fa819",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 96
        },
        "deepnote_cell_type": "code",
        "id": "lrrRuk6zLiF0"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "class SmallNet:\n",
        "    def __init__(self, in_features, num_hidden, dtype=np.float32):\n",
        "        self.W1 = np.zeros((num_hidden, in_features), dtype=dtype)\n",
        "        self.b1 = np.zeros((num_hidden, ), dtype=dtype)\n",
        "        self.W2 = np.zeros((1, num_hidden), dtype=dtype)\n",
        "        self.b2 = np.zeros((1,), dtype=dtype)\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n",
        "        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n",
        "        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n",
        "        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n",
        "        # TODO for Problem 2:\n",
        "        # set all parameters to small random values, e.g. from N(0, 0.5)\n",
        "        pass\n",
        "\n",
        "    def forward(self, X, Y=None, do_backward=False):\n",
        "        # TODO Problem 1: Fill in details of forward propagation\n",
        "\n",
        "        # Input to neurons in 1st layer\n",
        "        A1 = X@self.W1.T+self.b1\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O1 = sigmoid(A1)\n",
        "        # Inputs to neuron in the second layer\n",
        "        A2 = O1@self.W2.T+self.b2\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O2 = sigmoid(A2)\n",
        "\n",
        "        # When Y is none, simply return the predictions. Else compute the loss\n",
        "        if Y is not None:\n",
        "            loss = Y*np.log(O2) + (1-Y)*np.log(1 - O2)# TODO cross-entropy loss\n",
        "            # normalize loss by batch size\n",
        "            loss = - loss.sum() / X.shape[0]\n",
        "        else:\n",
        "            loss = np.nan\n",
        "\n",
        "        if do_backward:\n",
        "            # TODO in Problem 2:\n",
        "            # fill in the gradient computation\n",
        "            # Please note, that there is a correspondance between\n",
        "            # the forward and backward pass: with backward computations happening\n",
        "            # in reverse order.\n",
        "            # We save the gradients with respect to the parameters as fields of self.\n",
        "            # It is not very elegant, but simplifies training code later on.\n",
        "\n",
        "            # A2_grad is the gradient of loss with respect to A2\n",
        "            # Hint: there is a concise formula for the gradient\n",
        "            # of logistic sigmoid and cross-entropy loss\n",
        "            O2_grad = (O2-Y)/(O2-np.square(O2))\n",
        "            A2_grad = O2_grad*(sigmoid(A2)*(1 - sigmoid(A2)))\n",
        "            self.b2_grad = A2_grad.sum(0)/X.shape[0]\n",
        "            self.W2_grad = np.array([(O1*A2_grad).sum(0)/X.shape[0]])\n",
        "            O1_grad = self.W2*A2_grad\n",
        "            A1_grad = O1_grad*(sigmoid(A1)*(1 - sigmoid(A1)))\n",
        "            self.b1_grad = A1_grad.sum(0)/X.shape[0]\n",
        "            self.W1_grad = np.zeros(self.W1.shape)\n",
        "            for i in range(X.shape[0]):\n",
        "                self.W1_grad += (X[i][:, np.newaxis]*A1_grad[i]).T  \n",
        "            self.W1_grad /= X.shape[0]\n",
        "\n",
        "        return O2, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00017-32ce9293-0a37-4397-aeac-25eef428e8d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 102
        },
        "deepnote_cell_type": "code",
        "id": "jJswvBk0oiIY",
        "outputId": "ed749f40-83a2-4e62-a89b-fa2a7b079c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.546077501637665e-05\n",
            "XORnet([0. 0.]) = 4.543910487654591e-05\n",
            "XORnet([0. 1.]) = 0.999954519621495\n",
            "XORnet([1. 0.]) = 0.999954519621495\n",
            "XORnet([1. 1.]) = 4.543910487654575e-05\n"
          ]
        }
      ],
      "source": [
        "# TODO Problem 1:\n",
        "# Set by hand the weight values to solve the XOR problem\n",
        "\n",
        "\n",
        "\n",
        "net = SmallNet(2, 2, dtype=np.float64)\n",
        "net.W1 = np.array([[20, 20], [-20, -20]])\n",
        "net.b1 = np.array([[-10, 30]])\n",
        "net.W2 = np.ones((1,2))*20\n",
        "net.b2 = np.array([[-30]])\n",
        "\n",
        "# Hint: since we use the logistic sigmoid activation, the weights may need to\n",
        "# be fairly large\n",
        "\n",
        "predictions, loss = net.forward(X, Y, do_backward=True)\n",
        "print(loss)\n",
        "for x, p in zip(X, predictions):\n",
        "    print(f\"XORnet({x}) = {p[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00018-9f8740d2-90e7-4d20-a535-002df8547aba",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 108
        },
        "deepnote_cell_type": "markdown",
        "id": "wmxCi5Vl6_xB"
      },
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00019-8f804996-a00a-4bb5-a524-ad056659e023",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 114
        },
        "deepnote_cell_type": "code",
        "id": "eSM5hgJ1mrhY"
      },
      "outputs": [],
      "source": [
        "def check_grad(net, param_name, X, Y, eps=1e-5):\n",
        "    \"\"\"A gradient checking routine\"\"\"\n",
        "\n",
        "    param = getattr(net, param_name)\n",
        "    param_flat_accessor = param.reshape(-1)\n",
        "\n",
        "    grad = np.empty_like(param)\n",
        "    grad_flat_accessor = grad.reshape(-1)\n",
        "\n",
        "    net.forward(X, Y, do_backward=True)\n",
        "    orig_grad = getattr(net, param_name + \"_grad\")\n",
        "    assert param.shape == orig_grad.shape\n",
        "\n",
        "    for i in range(param_flat_accessor.shape[0]):\n",
        "        orig_val = param_flat_accessor[i]\n",
        "        param_flat_accessor[i] = orig_val + eps\n",
        "        _, loss_positive = net.forward(X, Y)\n",
        "        param_flat_accessor[i] = orig_val - eps\n",
        "        _, loss_negative = net.forward(X, Y)\n",
        "        param_flat_accessor[i] = orig_val\n",
        "        grad_flat_accessor[i] = (loss_positive - loss_negative) / (2 * eps)\n",
        "    \n",
        "    assert np.allclose(grad, orig_grad)\n",
        "    return grad, orig_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00020-1c4174cf-f129-4cad-adad-4734810a8ce1",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 120
        },
        "deepnote_cell_type": "code",
        "id": "TTZu0jFEvgXF"
      },
      "outputs": [],
      "source": [
        "# Hint: use float64 for checking the correctness of the gradient\n",
        "net = SmallNet(2, 2, dtype=np.float64)\n",
        "\n",
        "for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "    check_grad(net, param_name, X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00021-145837f8-c83f-4aab-8e62-0114e59f30fe",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 126
        },
        "deepnote_cell_type": "markdown",
        "id": "8mUOs3cVvjM2"
      },
      "source": [
        "## Problem 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00022-91b3eba0-6025-4839-847c-f5cb275fad07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 132
        },
        "deepnote_cell_type": "code",
        "id": "nn2AAoZo0vjU",
        "outputId": "f55609d1-4868-434f-a712-ccfb5e564bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after 0 steps \tloss=0.7026127050668588\n",
            "after 5000 steps \tloss=0.041810541367591145\n",
            "after 10000 steps \tloss=0.010635415218058929\n",
            "after 15000 steps \tloss=0.0057148634568882795\n",
            "after 20000 steps \tloss=0.0038262611962083005\n",
            "after 25000 steps \tloss=0.0028461615180759873\n",
            "after 30000 steps \tloss=0.002251853069875771\n",
            "after 35000 steps \tloss=0.0018553123342797077\n",
            "after 40000 steps \tloss=0.0015729991167978711\n",
            "after 45000 steps \tloss=0.0013623534926643765\n",
            "after 50000 steps \tloss=0.0011994962439535232\n",
            "after 55000 steps \tloss=0.0010700295669435575\n",
            "after 60000 steps \tloss=0.0009647738517922701\n",
            "after 65000 steps \tloss=0.0008776092816259686\n",
            "after 70000 steps \tloss=0.0008043041519806899\n",
            "after 75000 steps \tloss=0.0007418418595156353\n",
            "after 80000 steps \tloss=0.0006880158180248959\n",
            "after 85000 steps \tloss=0.0006411758454017326\n",
            "after 90000 steps \tloss=0.0006000639502067978\n",
            "after 95000 steps \tloss=0.0005637048662119873\n"
          ]
        }
      ],
      "source": [
        "net = SmallNet(2, 10, dtype=np.float64)\n",
        "\n",
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "for i in range(100000):\n",
        "    _, loss = net.forward(X, Y, do_backward=True)\n",
        "    if (i % 5000) == 0:\n",
        "        print(f\"after {i} steps \\tloss={loss}\")\n",
        "    for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "        param = getattr(net, param_name)\n",
        "        # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "        # Doing instead `param = new_val` simply changes to what the variable\n",
        "        # param points to, without affecting the network!\n",
        "        # alternatively, you could do setattr(net, param_name, new_value)\n",
        "        param[:] = param[:] - alpha*getattr(net, param_name + '_grad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00023-c92941a8-24d1-46e8-a410-d189c1d87b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 138
        },
        "deepnote_cell_type": "code",
        "id": "TwpEjpkU1JvK",
        "outputId": "ed15b05b-09da-4d3f-d398-f93975d243d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XORnet([0. 0.]) = 0.0003055298272821474\n",
            "XORnet([0. 1.]) = 0.9996220640425268\n",
            "XORnet([1. 0.]) = 0.9993536254684121\n",
            "XORnet([1. 1.]) = 0.00079484133934034\n"
          ]
        }
      ],
      "source": [
        "predictions, loss = net.forward(X, Y, do_backward=True)\n",
        "for x, p in zip(X, predictions):\n",
        "    print(f\"XORnet({x}) = {p[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00024-e09655a3-84e1-4a43-9b61-00edb56c6054",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 144
        },
        "deepnote_cell_type": "code",
        "id": "U0ZMyHqz8xrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be479fb-60a7-4c2d-8ae3-52223e6ce5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hudden_dim number: 2\n",
            "after 0 steps \tloss=0.7110607254814478\n",
            "after 5000 steps \tloss=0.693207422319511\n",
            "after 10000 steps \tloss=0.6930917791417205\n",
            "after 15000 steps \tloss=0.6928017751026287\n",
            "after 20000 steps \tloss=0.6750552931566346\n",
            "after 25000 steps \tloss=0.28086017678204334\n",
            "after 30000 steps \tloss=0.14108915521978377\n",
            "after 35000 steps \tloss=0.09052288467497333\n",
            "after 40000 steps \tloss=0.06579840236599296\n",
            "after 45000 steps \tloss=0.05140414988106337\n",
            "after 50000 steps \tloss=0.042061505738982416\n",
            "after 55000 steps \tloss=0.03553649034872278\n",
            "after 60000 steps \tloss=0.03073378642880377\n",
            "after 65000 steps \tloss=0.027056993241834054\n",
            "after 70000 steps \tloss=0.02415493572306482\n",
            "after 75000 steps \tloss=0.021807922863942092\n",
            "after 80000 steps \tloss=0.019871727396070443\n",
            "after 85000 steps \tloss=0.018247868729510255\n",
            "after 90000 steps \tloss=0.016866872307713422\n",
            "after 95000 steps \tloss=0.01567835864999345\n",
            "Hudden_dim number: 3\n",
            "after 0 steps \tloss=0.7044630792246446\n",
            "after 5000 steps \tloss=0.6931664052085303\n",
            "after 10000 steps \tloss=0.693093475961368\n",
            "after 15000 steps \tloss=0.6929937458503146\n",
            "after 20000 steps \tloss=0.6925307859237987\n",
            "after 25000 steps \tloss=0.6647341378026893\n",
            "after 30000 steps \tloss=0.0859198893429977\n",
            "after 35000 steps \tloss=0.02852545165286849\n",
            "after 40000 steps \tloss=0.016744496729319727\n",
            "after 45000 steps \tloss=0.011839602370975902\n",
            "after 50000 steps \tloss=0.009160930068210092\n",
            "after 55000 steps \tloss=0.007473771327303344\n",
            "after 60000 steps \tloss=0.006313388538159621\n",
            "after 65000 steps \tloss=0.005466184786054531\n",
            "after 70000 steps \tloss=0.004820308759846364\n",
            "after 75000 steps \tloss=0.004311525140118826\n",
            "after 80000 steps \tloss=0.003900312022957987\n",
            "after 85000 steps \tloss=0.0035610164706992194\n",
            "after 90000 steps \tloss=0.0032762599120887467\n",
            "after 95000 steps \tloss=0.0030338498248490024\n",
            "Hudden_dim number: 5\n",
            "after 0 steps \tloss=0.9126785839193827\n",
            "after 5000 steps \tloss=0.6929517240615254\n",
            "after 10000 steps \tloss=0.6496716900001329\n",
            "after 15000 steps \tloss=0.04166240319787587\n",
            "after 20000 steps \tloss=0.011868160146935038\n",
            "after 25000 steps \tloss=0.006205703654919117\n",
            "after 30000 steps \tloss=0.004043159857899957\n",
            "after 35000 steps \tloss=0.0029467486495893063\n",
            "after 40000 steps \tloss=0.002296551680612489\n",
            "after 45000 steps \tloss=0.0018707855835428718\n",
            "after 50000 steps \tloss=0.0015723242966328528\n",
            "after 55000 steps \tloss=0.0013524657071168275\n",
            "after 60000 steps \tloss=0.0011842943184007216\n",
            "after 65000 steps \tloss=0.0010518035727363141\n",
            "after 70000 steps \tloss=0.0009449134716205522\n",
            "after 75000 steps \tloss=0.0008569776825759866\n",
            "after 80000 steps \tloss=0.0007834455222935069\n",
            "after 85000 steps \tloss=0.000721101526068467\n",
            "after 90000 steps \tloss=0.0006676122401400315\n",
            "after 95000 steps \tloss=0.0006212450552243621\n",
            "Hudden_dim number: 10\n",
            "after 0 steps \tloss=0.8890746474660212\n",
            "after 5000 steps \tloss=0.6879254392134269\n",
            "after 10000 steps \tloss=0.058050859722519034\n",
            "after 15000 steps \tloss=0.01114593077743498\n",
            "after 20000 steps \tloss=0.005589357419323258\n",
            "after 25000 steps \tloss=0.0036345006408491764\n",
            "after 30000 steps \tloss=0.002662458774748323\n",
            "after 35000 steps \tloss=0.0020877751102427633\n",
            "after 40000 steps \tloss=0.0017106383069928491\n",
            "after 45000 steps \tloss=0.0014452292678632517\n",
            "after 50000 steps \tloss=0.0012488579146083336\n",
            "after 55000 steps \tloss=0.0010979932749234423\n",
            "after 60000 steps \tloss=0.0009786406521526958\n",
            "after 65000 steps \tloss=0.0008819740553184373\n",
            "after 70000 steps \tloss=0.0008021611698854932\n",
            "after 75000 steps \tloss=0.0007351983932637842\n",
            "after 80000 steps \tloss=0.0006782490896318212\n",
            "after 85000 steps \tloss=0.000629249005806931\n",
            "after 90000 steps \tloss=0.0005866612018522979\n",
            "after 95000 steps \tloss=0.0005493184618260311\n",
            "Hudden_dim number: 20\n",
            "after 0 steps \tloss=1.1477551282150695\n",
            "after 5000 steps \tloss=0.0810520531712841\n",
            "after 10000 steps \tloss=0.014607127555088584\n",
            "after 15000 steps \tloss=0.007080724069866373\n",
            "after 20000 steps \tloss=0.004507484112118208\n",
            "after 25000 steps \tloss=0.0032516877946314453\n",
            "after 30000 steps \tloss=0.0025195211226929364\n",
            "after 35000 steps \tloss=0.0020443414636234464\n",
            "after 40000 steps \tloss=0.0017130046301426728\n",
            "after 45000 steps \tloss=0.0014697783840815133\n",
            "after 50000 steps \tloss=0.0012841965269911823\n",
            "after 55000 steps \tloss=0.0011382693707740112\n",
            "after 60000 steps \tloss=0.00102072306211127\n",
            "after 65000 steps \tloss=0.0009241498269161707\n",
            "after 70000 steps \tloss=0.0008434906064611746\n",
            "after 75000 steps \tloss=0.000775177704196211\n",
            "after 80000 steps \tloss=0.0007166260295585544\n",
            "after 85000 steps \tloss=0.0006659185158788541\n",
            "after 90000 steps \tloss=0.0006216046583811484\n",
            "after 95000 steps \tloss=0.0005825675306910987\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# Generate data for a 3D XOR task\n",
        "# Then estimate the success rate of training the network with diferent\n",
        "# hidden sizes.\n",
        "\n",
        "X3 = np.array(np.meshgrid([0, 1], [0, 1], [0, 1])).T.reshape(-1,3)\n",
        "Y3 = np.logical_xor(np.logical_xor(X3[:,0],X3[:,1]), X3[:,2]).astype(int)[:, np.newaxis]\n",
        "\n",
        "\n",
        "for hidden_dim in [2, 3, 5, 10, 20]:\n",
        "    print(f'Hudden_dim number: {hidden_dim}')\n",
        "    # TODO: run a few trainings and record the fraction of successful ones\n",
        "    net = SmallNet(3, hidden_dim, dtype=np.float64)\n",
        "    \n",
        "    for i in range(100000):\n",
        "      _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "      if (i % 5000) == 0:\n",
        "          print(f\"after {i} steps \\tloss={loss}\")\n",
        "      for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "          param = getattr(net, param_name)\n",
        "          # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "          # Doing instead `param = new_val` simply changes to what the variable\n",
        "          # param points to, without affecting the network!\n",
        "          # alternatively, you could do setattr(net, param_name, new_value)\n",
        "          param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00025-9703bd09-6aae-4830-8221-09b53a623e4b",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 150
        },
        "deepnote_cell_type": "markdown",
        "id": "UuaLEoV-9DLG"
      },
      "source": [
        "## Problem 4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X3 = np.array(np.meshgrid([0, 1], [0, 1], [0, 1])).T.reshape(-1,3)\n",
        "Y3 = np.logical_xor(np.logical_xor(X3[:,0],X3[:,1]), X3[:,2]).astype(int)[:, np.newaxis]"
      ],
      "metadata": {
        "id": "rce39dEDpcbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00026-1a2be430-91e0-4209-ab3f-9ef84c39513b",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 156
        },
        "deepnote_cell_type": "code",
        "id": "w3lk9_TM-MvK"
      },
      "outputs": [],
      "source": [
        "class SmallNet4:\n",
        "    def __init__(self, in_features, num_hidden, dtype=np.float32):\n",
        "        self.W1 = np.zeros((num_hidden, in_features), dtype=dtype)\n",
        "        self.b1 = np.zeros((num_hidden, ), dtype=dtype)\n",
        "        self.W2 = np.zeros((1, num_hidden), dtype=dtype)\n",
        "        self.b2 = np.zeros((1,), dtype=dtype)\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n",
        "        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n",
        "        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n",
        "        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n",
        "        # TODO for Problem 2:\n",
        "        # set all parameters to small random values, e.g. from N(0, 0.5)\n",
        "        pass\n",
        "\n",
        "    def forward(self, X, Y=None, do_backward=False):\n",
        "        # TODO Problem 1: Fill in details of forward propagation\n",
        "\n",
        "        # Input to neurons in 1st layer\n",
        "        A1 = X@self.W1.T+self.b1\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O1 = np.maximum(A1, 0)\n",
        "        # Inputs to neuron in the second layer\n",
        "        A2 = O1@self.W2.T+self.b2\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O2 = sigmoid(A2)\n",
        "\n",
        "        # When Y is none, simply return the predictions. Else compute the loss\n",
        "        if Y is not None:\n",
        "            loss = Y*np.log(O2) + (1-Y)*np.log(1 - O2)# TODO cross-entropy loss\n",
        "            # normalize loss by batch size\n",
        "            loss = - loss.sum() / X.shape[0]\n",
        "        else:\n",
        "            loss = np.nan\n",
        "\n",
        "        if do_backward:\n",
        "            # TODO in Problem 2:\n",
        "            # fill in the gradient computation\n",
        "            # Please note, that there is a correspondance between\n",
        "            # the forward and backward pass: with backward computations happening\n",
        "            # in reverse order.\n",
        "            # We save the gradients with respect to the parameters as fields of self.\n",
        "            # It is not very elegant, but simplifies training code later on.\n",
        "\n",
        "            # A2_grad is the gradient of loss with respect to A2\n",
        "            # Hint: there is a concise formula for the gradient\n",
        "            # of logistic sigmoid and cross-entropy loss\n",
        "            O2_grad = (O2-Y)/(O2-np.square(O2))\n",
        "            A2_grad = O2_grad*(sigmoid(A2)*(1- sigmoid(A2)))\n",
        "            self.b2_grad = A2_grad.sum(0)/X.shape[0]\n",
        "            self.W2_grad = np.array([(O1*A2_grad).sum(0)/X.shape[0]])\n",
        "            O1_grad = self.W2*A2_grad\n",
        "            A1_grad = O1_grad*(A1 > 0).astype(int)\n",
        "            self.b1_grad = A1_grad.sum(0)/X.shape[0]\n",
        "            self.W1_grad = np.zeros(self.W1.shape)\n",
        "            for i in range(X.shape[0]):\n",
        "                self.W1_grad += (X[i][:, np.newaxis]*A1_grad[i]).T  \n",
        "            self.W1_grad /= X.shape[0]\n",
        "\n",
        "        return O2, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average loss function value after 20k iterations for diffrent hidden layer size.\n",
        "We can see that bigger hidden layer have better socre."
      ],
      "metadata": {
        "id": "6kOR2USELLHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([2, 3, 5, 10, 20])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in range(len(array)):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet4(3, array[hidden_dim], dtype=np.float64)\n",
        "        for i in range(20000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 20k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QCT8XeTo59-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a92ca9b3-2c1b-4e64-ec24-38d760640865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUgElEQVR4nO3debDlZX3n8fdHGhRZBELb0yzaGAiCTIDYIhmXGBGDwQhTZRHRMm0Gp8PEZDTJjBBrFnVMgpkqnVgmqRAhdjKyFcoSSKIUgWgSRbuVRDYHxCaA3XSrILQry3f++D2Nh8u9fU/3XU4e+v2qOnV+++/7nHvP5zznOVuqCklSf5426QIkSTvGAJekThngktQpA1ySOmWAS1KnDHBJ6pQBrlkluT7JWyddB0CSlyS5PcmWJKdOup6pkqxP8qoxt92S5HkLXdM2zv+yJF+Z1Pk1dwb4U0AL2PuTPH3StSyC9wIfrqo9q+ryJJXk0Pk6eJJnJ7kwydeTfDvJPyR58ZRt3pjkriTfSXJ5kv125FytDXe2Y340yfvmow0zmXpbVdVnqurwhTynFpYB3rkkK4CXAQW8brLVLIrnAjfPx4GSLJlm8Z7AF4AXAvsBa4Crk+zZ9nkB8CfAm4FlwHeBP5qPeuZihrboqa6qvHR8Af4H8A/AB4Cr2rKnAw8AR41stxT4HvDsNv9OYAPwdeCtDA8Ah85wjuuBt7bppwH/DbgL2AT8OfCstu4ZwP8FvtnO/wVgWVv3FuBO4CHga8CbZjjXccBn2/4bgA8Du7V1XwUea+3Y0rYr4Dtt/hfbdq8FbmzH+EfgJ0eOvx44C/hn4AfAkjFu4weBF7bp3wUuGFn348APgb1Gjv+qNn1Ea+vpMxy3gEOB1cDD7ThbgL9s6w8APg5sbsf5zyP7vhu4tN3eD7a/4bZuu09Pva2AVwD3jBzziPa3foDhQfJ1I+s+CvwhcHX7G94A/HhbF+CD7f/hQeDLjPzveVnA+/+kC/Ayxz8g3AH8KkOP8eGRwDwf+J2R7d4G/E2bPgnYCLwAeGYLgXED/D+0cz6Pobf6CeAv2rpfAf6yHXOXVtPewB7tjn1422458IIZzvVC4HhgCbACuBV4x8j6xwOyzT+hbuDYFiQvbjWsavs8fWT/G4GDgd3HuH2PAb7Pjx6krgDOmrLNFn4U8OuBVwE/BfwL8NptHPvx2ltAvm9k3dOAdQwP0Lu12/tO4Ofa+ne3v/epbdvdx7jtpt5Wr6AFOLBr+7u+q53vlQxBffhIfd9keJBYAnwMuKit+7lW6z4MYX4EsHzS942d4eIQSseSvJRhSOGSqlrH0EN9Y1t9AfCGkc3f2JYBnAb8WVXdXFXfZQiDcb0J+EBV3VlVW4DfBt7QnsI/DPwYQ0g8WlXrqurBtt9jwFFJdq+qDVU17TBI2+dzVfVIVa1nGK74me2obzXwJ1V1Q6thDUNP+/iRbT5UVXdX1fe2daAkewN/Abynqr7dFu8JfHvKpt8G9hqZfxlwJfBLVXXVdtQ+6kXA0qp6b1X9sIax8j/liX/Tz1bV5VX1WFV9b4633fEMbTunne9vgauA00e2uayqPl9VjzAE+DFt+cMM7X8+kKq6tao27FiztT0M8L6tAj5VVd9o8xe0ZQDXAc9M8uI2Tn4McFlbdwBw98hxRqdncwDD8MlWdzH0yJYxhN0ngYvai4C/n2TXqvoOw1P2M4ENSa5O8vzpDp7kJ5JclWRjkgcZhiz23476ngv8VpIHtl4YetsHjGwza3uT7M7wbOJzVfV7I6u2MDyrGLU3Q291qzOBf6yq67ej7qmeCxwwpR3vYridt3pCO+Z42x0A3F1Vj40suws4cGR+48j0dxkCnxb2H2YYYtmU5Nz24KcFZoB3qgXMacDPtDvsRuA3gKOTHF1VjwKXMPSgTmcYH98aMhuAg0YOd/B2nPrrDOGy1XOAR4D7qurhqnpPVR0J/DuGsehfAqiqT1bViQzDJ7cx9Can88dt/WFVtTdDaGU76rubYehon5HLM6vqwpFttvkVnO3dPJcD9zAMC426GTh6ZNvnMbzm8P9GtjkTeE6SD25H3VNruhv42pR27FVVP7+NfeZy230dODjJaCY8B7h3rOKrPlRVLwSOBH4C+K9jnldzYID361TgUYY7zDHtcgTwGVpoMvTIf5Fh2OOCkX0vAX45yRFJngn89+0474XAbyQ5pL0z43eBi6vqkSQ/m+TfJtmFYcz7YeCxJMuSnJJkD4bhjC0MQyrT2avtu6X10v/TLPXcxzA+vNWfAme2Zx5JskeSk5PsNcP+T5BkV4YXB78HrJrSI4Vh6OAX2nuo92B4W+MnRh4cYeiNnwS8PMk545x3mnZ8HngoyVlJdk+yS5KjkrxoG8eY7babeo5RNzD0qt+ZZNckrwB+AbhotsKTvKjd3rsyvEj6fWb++2oeGeD9WsUwjv0vVbVx64XhqeybkiypqhsY7lAHAH+9dceq+mvgQwzDLHcAn2urfjDGec9nGCr5NMM7I74P/Hpb928Ywu9BhhfQ/q5t+zTgNxl6ed9iGJedKZj/C8N4/UMMYXzxLPW8G1jThhlOq6q1wH9kuB3ub+17yxjt2mrrM4dXAw+0D9tsSfIygDZ2fyZDkG9iCM1fnXqQqnoAOBF4TZL/NcZ5zwOObO24vD2Dei3DA/PXgG8AHwGetY1jzHbbvZuR22pKvT9kCOzXtHP9EcMY/m1j1L53O9/9DMMu3wT+9xj7aY5S5Q867OySHAHcxPBOjUcmXY+k8dgD30kl+fdJnp5kX+D9DO89NryljhjgO69fYRgC+CrDWPpsY82S/pVxCEWSOmUPXJI6tahfgLP//vvXihUrFvOUktS9devWfaOqlk5dvqgBvmLFCtauXbuYp5Sk7iW5a7rlDqFIUqcMcEnqlAEuSZ0aK8CT7JPk0iS3Jbk1yU8n2S/JNRl+n/Ca9oEQSdIiGbcH/gcMPwbwfIZvYrsVOBu4tqoOA65t85KkRTJrgCd5FvByhi/boX3Z+wPAKQy/F0i7PnVhSpQkTWecHvghDL/J92dJvpTkI+1rNJeN/OrGRp74RfOPS7I6ydokazdv3jw/VUuSxgrwJQy/7/fHVXUsw9eTPmG4pIbP40/7mfyqOreqVlbVyqVLn/Q+dEnSDhonwO9h+OHTG9r8pQyBfl+S5QDtetPClChJms6sn8Ssqo1J7k5yeFV9BTgBuKVdVgHntOsrFrLQFWdfvZCHX1Trzzl50iVIegoY96P0vw58LMluwJ3ALzP03i9JcgbDr3Ccto39JUnzbKwAr6obgZXTrDphXquRJI3NT2JKUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnq1JJxNkqyHngIeBR4pKpWJtkPuBhYAawHTquq+xemTEnSVNvTA//Zqjqmqla2+bOBa6vqMODaNi9JWiRzGUI5BVjTptcAp865GknS2MYN8AI+lWRdktVt2bKq2tCmNwLLptsxyeoka5Os3bx58xzLlSRtNdYYOPDSqro3ybOBa5LcNrqyqipJTbdjVZ0LnAuwcuXKabeRJG2/sXrgVXVvu94EXAYcB9yXZDlAu960UEVKkp5s1gBPskeSvbZOA68GbgKuBFa1zVYBVyxUkZKkJxtnCGUZcFmSrdtfUFV/k+QLwCVJzgDuAk5buDIlSVPNGuBVdSdw9DTLvwmcsBBFSZJm5ycxJalTBrgkdcoAl6ROGeCS1CkDXJI6Ne4nMTVBK86+etIlzJv155w86RKkpwx74JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6tTYAZ5klyRfSnJVmz8kyQ1J7khycZLdFq5MSdJU29MDfztw68j8+4EPVtWhwP3AGfNZmCRp28YK8CQHAScDH2nzAV4JXNo2WQOcugD1SZJmMG4P/P8A7wQea/M/BjxQVY+0+XuAA6fbMcnqJGuTrN28efNcapUkjZg1wJO8FthUVet25ARVdW5VrayqlUuXLt2RQ0iSprFkjG1eArwuyc8DzwD2Bv4A2CfJktYLPwi4d+HKlCRNNWsPvKp+u6oOqqoVwBuAv62qNwHXAa9vm60CrliwKiVJTzKX94GfBfxmkjsYxsTPm5+SJEnjGGcI5XFVdT1wfZu+Ezhu/kuSJI3DT2JKUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnq1KwBnuQZST6f5J+S3JzkPW35IUluSHJHkouT7Lbw5UqSthqnB/4D4JVVdTRwDHBSkuOB9wMfrKpDgfuBMxasSknSk8wa4DXY0mZ3bZcCXglc2pavAU5diAIlSdMbaww8yS5JbgQ2AdcAXwUeqKpH2ib3AAfOsO/qJGuTrN28efM8lCxJgjEDvKoerapjgIOA44Dnj3uCqjq3qlZW1cqlS5fuWJWSpCfZrnehVNUDwHXATwP7JFnSVh0E3Du/pUmStmWcd6EsTbJPm94dOBG4lSHIX982WwVcsUA1SpKmsWT2TVgOrEmyC0PgX1JVVyW5BbgoyfuALwHnLWCdkqQpZg3wqvpn4Nhplt/JMB4uSZoAP4kpSZ0ywCWpUwa4JHVqnBcxpYlacfbVky5h3qw/5+RJl6CnEHvgktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpU7MGeJKDk1yX5JYkNyd5e1u+X5Jrktzervdd+HIlSVuN0wN/BPitqjoSOB54W5IjgbOBa6vqMODaNi9JWiSzBnhVbaiqL7bph4BbgQOBU4A1bbM1wKkLVKMkaRrbNQaeZAVwLHADsKyqNrRVG4FlM+yzOsnaJGs3b948l1olSSPGDvAkewIfB95RVQ+OrquqAmq6/arq3KpaWVUrly5dOqdiJUk/MlaAJ9mVIbw/VlWfaIvvS7K8rV8ObFqYEiVJ0xnnXSgBzgNuraoPjKy6EljVplcBV8x/eZKkmSwZY5uXAG8GvpzkxrbsXcA5wCVJzgDuAk5bkAolSdOaNcCr6u+BzLD6hPktR5I0Lj+JKUmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVOzBniS85NsSnLTyLL9klyT5PZ2ve/ClilJmmqcHvhHgZOmLDsbuLaqDgOubfOSpEU0a4BX1aeBb01ZfAqwpk2vAU6d37IkSbPZ0THwZVW1oU1vBJbNtGGS1UnWJlm7efPmHTydJGmqOb+IWVUF1DbWn1tVK6tq5dKlS+d6OklSs6MBfl+S5QDtetP8lSRJGseOBviVwKo2vQq4Yn7KkSSNa5y3EV4IfBY4PMk9Sc4AzgFOTHI78Ko2L0laREtm26CqTp9h1QnzXIskaTv4SUxJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnq1Ky/yCNpclacffWkS5g36885edIlPOXYA5ekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ak4BnuSkJF9JckeSs+erKEnS7HY4wJPsAvwh8BrgSOD0JEfOV2GSpG2bSw/8OOCOqrqzqn4IXAScMj9lSZJmk6rasR2T1wMnVdVb2/ybgRdX1a9N2W41sLrNHg58ZcfLXXD7A9+YdBETtDO3f2duO+zc7e+h7c+tqqVTFy74l1lV1bnAuQt9nvmQZG1VrZx0HZOyM7d/Z2477Nzt77ntcxlCuRc4eGT+oLZMkrQI5hLgXwAOS3JIkt2ANwBXzk9ZkqTZ7PAQSlU9kuTXgE8CuwDnV9XN81bZZHQx1LOAdub278xth527/d22fYdfxJQkTZafxJSkThngktQpAxxIcnCS65LckuTmJG+fdE2LJckzknw+yT+1tr9n0jUttiTrk3w5yY1J1k66noWU5Pwkm5LcNLJsvyTXJLm9Xe87yRoXykz3857b7xg4kGQ5sLyqvphkL2AdcGpV3TLh0hZckgB7VNWWJLsCfw+8vao+N+HSFk2S9cDKqvrX/mGOOUvycmAL8OdVdVRb9vvAt6rqnPadRvtW1VmTrHMhzHQ/B95Cp+23Bw5U1Yaq+mKbfgi4FThwslUtjhpsabO7touP6k9RVfVp4FtTFp8CrGnTaxhC7SlnG/fzbttvgE+RZAVwLHDDhEtZNEl2SXIjsAm4pqp2mrY3BXwqybr21Q87m2VVtaFNbwSWTbKYxTDlft5t+w3wEUn2BD4OvKOqHpx0PYulqh6tqmMYPk17XJKjJlzSYntpVf0Uwzdrvq0NM+yUahhTfUo/A9vW/by39hvgTRv//Tjwsar6xKTrmYSqegC4DjhpwqUsqqq6t11vAi5j+KbNncl9bXx46zjxpgnXs2BmuJ93234DnMdfyDsPuLWqPjDpehZTkqVJ9mnTuwMnArdNtKhFlGSP9oIWSfYAXg3ctO29nnKuBFa16VXAFROsZcFs437ebft9FwqQ5KXAZ4AvA4+1xe+qqr+aXFWLI8lPMrxwswvDA/olVfXeyVa1eJI8j6HXDcNXS1xQVb8zwZIWVJILgVcwfIXqfcD/BC4HLgGeA9wFnFZVU1/o7N5M93OGcfAu22+AS1KnHEKRpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalT/x9HBc+RIl1zoAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see diffrences better I multyply result by 100"
      ],
      "metadata": {
        "id": "LgimEtjJLwi1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00027-de8a387d-3b6a-48d5-b6c8-fddf13637e38",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 162
        },
        "deepnote_cell_type": "markdown",
        "id": "_Hr_iAKX-ND1"
      },
      "source": [
        "## Problem 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00028-0aa6ea62-907d-44bf-9ba4-71870d3dd547",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 168
        },
        "deepnote_cell_type": "code",
        "id": "rnz6CndQ-NRI"
      },
      "outputs": [],
      "source": [
        "class SmallNet5:\n",
        "    def __init__(self, in_features, num_hidden, dtype=np.float32):\n",
        "        self.W1 = np.zeros((num_hidden, in_features), dtype=dtype)\n",
        "        self.b1 = np.zeros((num_hidden, ), dtype=dtype)\n",
        "        self.W2 = np.zeros((num_hidden, num_hidden), dtype=dtype)\n",
        "        self.b2 = np.zeros((num_hidden,), dtype=dtype)\n",
        "        self.W3 = np.zeros((1, num_hidden), dtype=dtype)\n",
        "        self.b3 = np.zeros((1,), dtype=dtype)\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n",
        "        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n",
        "        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n",
        "        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n",
        "        self.W3 = np.random.normal(0, 0.5, self.W3.shape)\n",
        "        self.b3 = np.random.normal(0, 0.5, self.b3.shape)\n",
        "        # TODO for Problem 2:\n",
        "        # set all parameters to small random values, e.g. from N(0, 0.5)\n",
        "        pass\n",
        "\n",
        "    def forward(self, X, Y=None, do_backward=False):\n",
        "        # TODO Problem 1: Fill in details of forward propagation\n",
        "\n",
        "        # Input to neurons in 1st layer\n",
        "        A1 = X@self.W1.T+self.b1\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O1 = np.maximum(A1, 0)\n",
        "        # Inputs to neuron in the second layer\n",
        "        A2 = O1@self.W2.T+self.b2\n",
        "        # Outputs after the sigmoid non-linearity\n",
        "        O2 = np.maximum(A2, 0)\n",
        "\n",
        "        A3 = O2@self.W3.T+self.b3\n",
        "\n",
        "        O3 = sigmoid(A3)\n",
        "\n",
        "        # When Y is none, simply return the predictions. Else compute the loss\n",
        "        if Y is not None:\n",
        "            loss = Y*np.log(O3) + (1-Y)*np.log(1 - O3)# TODO cross-entropy loss\n",
        "            # normalize loss by batch size\n",
        "            loss = - loss.sum() / X.shape[0]\n",
        "        else:\n",
        "            loss = np.nan\n",
        "\n",
        "        if do_backward:\n",
        "            # TODO in Problem 2:\n",
        "            # fill in the gradient computation\n",
        "            # Please note, that there is a correspondance between\n",
        "            # the forward and backward pass: with backward computations happening\n",
        "            # in reverse order.\n",
        "            # We save the gradients with respect to the parameters as fields of self.\n",
        "            # It is not very elegant, but simplifies training code later on.\n",
        "\n",
        "            # A2_grad is the gradient of loss with respect to A2\n",
        "            # Hint: there is a concise formula for the gradient\n",
        "            # of logistic sigmoid and cross-entropy loss\n",
        "            \n",
        "            # Output layer\n",
        "            O3_grad = (O3-Y)/(O3-np.square(O3))\n",
        "            A3_grad = O3_grad*(sigmoid(A3)*(1 - sigmoid(A3)))\n",
        "            self.b3_grad = A3_grad.sum(0)/X.shape[0]\n",
        "            self.W3_grad = np.array([(O2*A3_grad).sum(0)/X.shape[0]])\n",
        "            \n",
        "            # 2 Hidden layer\n",
        "          \n",
        "            O2_grad = self.W3*A3_grad\n",
        "            A2_grad = O2_grad*(A2 > 0).astype(int)\n",
        "            self.b2_grad = A2_grad.sum(0)/X.shape[0]\n",
        "            self.W2_grad = np.zeros(self.W2.shape)\n",
        "            for i in range(X.shape[0]):\n",
        "                self.W2_grad += (O1[i][:, np.newaxis]*A2_grad[i]).T  \n",
        "            self.W2_grad /= X.shape[0]\n",
        "\n",
        "            # 1 Hidden layer\n",
        "            O1_grad = np.zeros((O1.shape))\n",
        "            for i in range(self.W1.shape[0]):\n",
        "                O1_grad += A2_grad[:,i][:, np.newaxis]@self.W2[i].reshape(1,self.W2.shape[0])\n",
        "            #O1_grad /= self.W1.shape[0]\n",
        "\n",
        "            A1_grad = O1_grad*(A1 > 0).astype(int)\n",
        "            self.b1_grad = A1_grad.sum(0)/X.shape[0]\n",
        "            self.W1_grad = np.zeros(self.W1.shape)\n",
        "            for i in range(X.shape[0]):\n",
        "                self.W1_grad += (X[i][:, np.newaxis]*A1_grad[i]).T\n",
        "            self.W1_grad /= X.shape[0]\n",
        "\n",
        "        return O2, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function for 3DXor problem on 2 hidden layers every have size of 20"
      ],
      "metadata": {
        "id": "_0QqhMD2K4Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([2, 3, 5, 10, 20])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in range(len(array)):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet5(3, array[hidden_dim], dtype=np.float64)\n",
        "        for i in range(20000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 20k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OD_nQKMypUjL",
        "outputId": "f6666fbc-7998-43e5-e7ea-f5322e6389b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SmallNet5(3, 3, dtype=np.float64)\n",
        "\n",
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "result = np.zeros((100000,))\n",
        "\n",
        "for i in range(100000):\n",
        "    _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "    for param_name in [\"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"]:\n",
        "        param = getattr(net, param_name)\n",
        "        param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "    result[i] = loss\n",
        "\n",
        "plt.title(\"Loss function\")\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"Loss function\")\n",
        "plt.plot(np.arange(100000), result)\n",
        "\n",
        "print(f'Last loss value: {result[99999]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "GXEmpuGW8HpT",
        "outputId": "1860c8a3-29b4-4cc1-8093-9411f6372072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last loss value: 1.2371485144426052e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfSElEQVR4nO3de5wdZZ3n8c+3OyRB7pJWLgkkOJGZ6Chgi7iyLqugwXUSd0QN3kBxsjobRdFxwuiykNndl8LIqGNcyYzorIIBr9Ni3HgD72A6EMAEA23k0gGhud8hl9/8Uc/pFCenTp++VJ/uru/79TqvrnrqOVW/SjX946mn6nkUEZiZmQF0tDsAMzObOJwUzMxskJOCmZkNclIwM7NBTgpmZjbIScHMzAY5KZi1SNKekr4r6SFJXx/nY2+UdMJ4HtOqaVq7AzAbLkm3Au+JiB+N86FPAZ4LHBgR28s6iKQvA/0R8fFaWUS8oKzjmeW5pWDWusOBm8tMCGbt5qRgU4akGZI+LenO9Pm0pBlp2yxJV0h6UNL9kn4uqSNt+1tJWyU9ImmzpFc32Pd5wDnAWyQ9KukMSedK+mquzlxJIWlaWr9K0t9L+mXa9w8kzcrVP17Sr1JMd0g6XdJS4G3AR9Nxvpvq3irpxBbO8wRJ/ZI+LOkeSXdJeldZ/+Y29Tgp2FTyMeA44CjgxcCxQO0WzIeBfqCL7BbQ3wEh6UhgGfDSiNgHeC1wa/2OI+J/Av8HuCwi9o6IL7YY01uBdwHPAaYDHwGQdDjwfeCfUkxHARsiYhVwCXB+Os5fDPM8AQ4C9gMOBc4AVko6oMV4reKcFGwqeRuwIiLuiYgB4DzgHWnbNuBg4PCI2BYRP49s4K8dwAxggaQ9IuLWiPj9GMb0pYi4OSKeAC4n+0MOWbL4UUR8LcVzX0RsaHGfzc4TsnNdkfa7BngUOHIsTsamPicFm0oOAW7Lrd+WygAuAPqAH0jaImk5QET0AR8EzgXukbRa0iGMnT/mlh8H9k7Lc4CRJp9m5wlwX12/R/64Zk05KdhUcidZZ3DNYamMiHgkIj4cEUcAi4Czan0HEXFpRByfvhvAJ1s83mPAs3LrBw0j1juA5xVsG2ro4sLzNBstJwWbrPaQNDP3mQZ8Dfi4pK7UoXsO8FUASa+X9CeSBDxEdttop6QjJb0qddQ+CTwB7Gwxhg3AKyUdJmk/4OxhxH8JcKKkN0uaJulASUelbXcDRzT5buF5mo2Wk4JNVmvI/oDXPucC/wvoBW4AbgSuTWUA84Efkd1f/zXw+Yi4kqw/4RPAvWS3ep5Di3/cI+KHwGXpeOuBK1oNPiJuB15H1gF+P1mCeXHa/EWyPo4HJX2nwdebnafZqMiT7JiZWY1bCmZmNshJwczMBjkpmJnZICcFMzMbNOlGSZ01a1bMnTu33WGYmU0q69evvzciuoaqN+mSwty5c+nt7W13GGZmk4qk24au5dtHZmaW46RgZmaDSk0Kkham8en7agOQ1W0/TNKVkq6TdIOk15UZj5mZNVdaUpDUCawETgYWAKdKWlBX7ePA5RFxNLAE+HxZ8ZiZ2dDKbCkcC/RFxJaIeBpYDSyuqxPAvml5PzzSo5lZW5WZFA4lGx64pj+V5Z0LvF1SP9kAZ+9vtCNJSyX1SuodGBgoI1YzM6P9Hc2nAl+OiNlkI0Z+pTZvbl5ErIqI7ojo7uoa8jFbMzMboTKTwlay2aVqZqeyvDPIpigkIn4NzARmUYJ1t97Pp36wmae3tzpUvplZ9ZSZFNYB8yXNkzSdrCO5p67O7cCrAST9GVlSKOX+0LW3PcA//aSP7TudFMzMipSWFNIcscuAtcBNZE8ZbZS0QtKiVO3DwF9Jup5sNqnTo6QJHqTs505PH2FmVqjUYS4iYg1ZB3K+7Jzc8ibgFWXGUCNUO+Z4HM7MbFJqd0fzuKm1FJwSzMyKVSgppJaCuxTMzApVJil0DLYU3FYwMytSmaSQcoI7ms3MmqhOUpA7ms3MhlKZpNDhR1LNzIZUmaRQe/zIfQpmZsUqkxRqLQXnBDOzYpVJCrWX13z7yMysWGWSgh9JNTMbWmWSgsc+MjMbWnWSgsc+MjMbUnWSQu32kXOCmVmhCiWFWkuhzYGYmU1glUkK7mg2MxtaZZKCO5rNzIZWalKQtFDSZkl9kpY32P6Pkjakz82SHiwtFnc0m5kNqbSZ1yR1AiuBk4B+YJ2knjTbGgAR8aFc/fcDR5cXTzpmWQcwM5sCymwpHAv0RcSWiHgaWA0sblL/VLJ5mkvhUVLNzIZWZlI4FLgjt96fynYj6XBgHvCTgu1LJfVK6h0YGBhRMB1+JNXMbEgTpaN5CfCNiNjRaGNErIqI7ojo7urqGtEBPPaRmdnQykwKW4E5ufXZqayRJZR46whg+rTsVJ/a3jDvmJkZ5SaFdcB8SfMkTSf7w99TX0nSnwIHAL8uMRYO3Hs6AD/53T1lHsbMbFIrLSlExHZgGbAWuAm4PCI2SlohaVGu6hJgdZTcA3zQvjMB+PSPbinzMGZmk1ppj6QCRMQaYE1d2Tl16+eWGUPNIfvvOR6HMTOb1CZKR/O4ecnhB7Q7BDOzCatySWH9bQ+0OwQzswmrcknBzMyKVSopHNG1V7tDMDOb0ErtaJ5oXn7EgTz0+LZ2h2FmNmFVqqXQ2SF2eJwLM7NClUoKHRI7PM6FmVmhSiWFzg6x00nBzKxQ5ZKCbx+ZmRWrVFLokNi5s91RmJlNXJVKCp0duKVgZtZEtZKCO5rNzJqqVFLoSNOvubPZzKyxSiWFzjRPs28hmZk1VqmkUGsp+BaSmVljlUoKnbXbR24pmJk1VGpSkLRQ0mZJfZKWF9R5s6RNkjZKurTMeGq3j9xQMDNrrLQB8SR1AiuBk4B+YJ2knojYlKszHzgbeEVEPCDpOWXFkx0v++nbR2ZmjZXZUjgW6IuILRHxNLAaWFxX56+AlRHxAEBE3FNiPLtuHzkpmJk1VGZSOBS4I7fen8ryng88X9IvJV0taWGjHUlaKqlXUu/AwMCIA6olBT99ZGbWWLs7mqcB84ETgFOBf5a0f32liFgVEd0R0d3V1TXig3XILQUzs2bKTApbgTm59dmpLK8f6ImIbRHxB+BmsiRRCrcUzMyaKzMprAPmS5onaTqwBOipq/MdslYCkmaR3U7aUlZAgy+vuaVgZtZQaUkhIrYDy4C1wE3A5RGxUdIKSYtStbXAfZI2AVcCfxMR95UV065hLso6gpnZ5FbqHM0RsQZYU1d2Tm45gLPSp3SdKQX69pGZWWPt7mgeVx2+fWRm1lSlkoKHuTAza65aScEtBTOzpiqVFDxKqplZc5VKCrsGxHNSMDNrpFpJwS0FM7OmKpUUBt9TcE4wM2uoWkkhDZ3t20dmZo1VKin46SMzs+YqlRQ6PJ+CmVlTlUoKHiXVzKy5SiUFD3NhZtZcpZKCh7kwM2uuWklhsKXQ5kDMzCaoSiWFjtrQ2b59ZGbWUEvzKUjqBJ6brx8Rt5cVVFl8+8jMrLkhWwqS3g/cDfwQ+F76XNHKziUtlLRZUp+k5Q22ny5pQNKG9HnPMOMfFr+nYGbWXCsthTOBI4c7TWZqXawETgL6gXWSeiJiU13VyyJi2XD2PVIdbimYmTXVSp/CHcBDI9j3sUBfRGyJiKeB1cDiEexnzLilYGbWXCsthS3AVZK+BzxVK4yIC4f43qFkCaWmH3hZg3pvlPRK4GbgQxFxR30FSUuBpQCHHXZYCyE35lFSzcyaa6WlcDtZf8J0YJ/cZyx8F5gbES9Kx/jXRpUiYlVEdEdEd1dX14gP5ttHZmbNDdlSiIjzACTtndYfbXHfW4E5ufXZqSy/73w/xb8A57e47xHZNclOmUcxM5u8Wnn66IWSrgM2AhslrZf0ghb2vQ6YL2mepOnAEqCnbt8H51YXATe1Hvrw1YbO9u0jM7PGWulTWAWcFRFXAkg6Afhn4D80+1JEbJe0DFgLdAIXR8RGSSuA3ojoAT4gaRGwHbgfOH2E59ES3z4yM2uulaSwVy0hAETEVZL2amXnEbEGWFNXdk5u+Wzg7BZjHTU/fWRm1lxLTx9J+h/AV9L628meSJp0Ovz0kZlZU608ffRuoAv4Vvp0pbJJx8NcmJk118rTRw8AHxiHWErnUVLNzJorTAqSPh0RH5T0XWC3/7WOiEWlRlaC2iipbimYmTXWrKVQ60P4h/EIZDy4o9nMrLnCpBAR69PiURHxmfw2SWcCPy0zsDJ4mAszs+Za6Wg+rUHZ6WMcx7iQhOTbR2ZmRZr1KZwKvBWYJyn/JvI+ZC+aTUqdklsKZmYFmvUp/Aq4C5gFfCpX/ghwQ5lBlamjQ+xwS8HMrKFmfQq3AbdJehtwZ0Q8CSBpT7LB7W4dlwjHWKfETrcUzMwaaqVP4XIg/2T/DuDr5YRTvs4O+T0FM7MCrSSFaWnmNADS8vTyQiqXO5rNzIq1khQG0kimAEhaDNxbXkjl6uyQk4KZWYFWBsR7L3CJpM8BIpti852lRlUiP31kZlaslbGPfg8cN4KZ1yakDrcUzMwKDZkUJM0A3gjMBaYpDRUREStKjawkbimYmRVrpU/h34DFZLOjPZb7DEnSQkmbJfVJWt6k3hslhaTuVvY7Gn76yMysWCt9CrMjYuFwdyypE1gJnAT0A+sk9UTEprp6+wBnAtcM9xgj0dHhp4/MzIq00lL4laQ/H8G+jwX6ImJLeox1NVmLo97fA58EnhzBMYbNt4/MzIq1khSOB9an20A3SLpRUivDXBxK9qRSTX8qGyTpGGBORHyv2Y4kLZXUK6l3YGCghUMX8zAXZmbFWrl9dHIZB5bUAVxICyOuRsQqYBVAd3f3qP6ie5gLM7NirbQUouAzlK3AnNz67FRWsw/wQuAqSbcCxwE9ZXc2Zx3NTgpmZo200lL4HlkSEDATmAdsBl4wxPfWAfMlzSNLBkvIhuIGICIeIhuBFQBJVwEfiYjeYcQ/bB3yewpmZkVaeXntGZ3MqR/gr1v43nZJy4C1QCdwcURslLQC6I2InuZ7KIdbCmZmxVppKTxDRFwr6WUt1l0DrKkrO6eg7gnDjWUkso7m8TiSmdnk08obzWflVjuAY4A7S4uoZJ3CHc1mZgVaaSnsk1veTtbH8M1ywimf+xTMzIo1m6P5KxHxDuDBiPjMOMZUqg73KZiZFWr2SOpLJB0CvFvSAZKenf+MV4BjrdMtBTOzQs1uH30B+DFwBLCe7JHUmkjlk05nh3hqu5OCmVkjhS2FiPhsRPwZ2aOkR0TEvNxnUiYE8NNHZmbNDPlGc0S8bzwCGS9++sjMrFgrw1xMKX55zcysWOWSgh9JNTMrNmRSkLRXGtEUSc+XtEjSHuWHVg63FMzMirXSUvgZMFPSocAPgHcAXy4zqDJ5PgUzs2KtJAVFxOPAXwKfj4g3MfQIqROW51MwMyvWUlKQ9HLgbWRDXEA26umk1OmWgplZoVaSwgeBs4Fvp6GvjwCuLDWqEnVI7NzZ7ijMzCamVuZT+CnwUxicQvPeiPhA2YGVpbMDdzSbmRVo5emjSyXtK2kv4LfAJkl/U35o5fDtIzOzYq3cPloQEQ8DbwC+TzYd5zta2bmkhZI2S+qTtLzB9vdKulHSBkm/kLRgOMGPhCTCScHMrKFWksIe6b2ENwA9EbGNbEC8piR1AiuBk4EFwKkN/uhfGhF/HhFHAecDFw4j9hHplN9TMDMr0kpSuAi4FdgL+Jmkw4GHW/jesUBfRGyJiKeB1cDifIXUAqnZixaSzWh1CJwTzMwaa6Wj+bPAZ3NFt0n6zy3s+1Dgjtx6P7Db3M6S/jtwFjAdeFUL+x0V3z4yMyvWSkfzfpIulNSbPp8i+7/6MRERKyPiecDfAh8viGFp7fgDAwOjOl6HhHOCmVljrdw+uhh4BHhz+jwMfKmF720F5uTWZ6eyIqvJ+i12ExGrIqI7Irq7urpaOHSx7PaRs4KZWSND3j4CnhcRb8ytnydpQwvfWwfMlzSPLBksAd6aryBpfkTcklb/C3ALJZP7FMzMCrWSFJ6QdHxE/AJA0iuAJ4b6UkRsl7QMWEs2LMbF6Y3oFUBvRPQAyySdCGwDHgBOG+mJtKpDIsrvzzYzm5RaSQrvBf6fpP3Sest/vCNiDbCmruyc3PKZLcY5ZiS5pWBmVqCVp4+uB14sad+0/rCkDwI3lBxbKST89JGZWYGWZ16LiIdz7xWcVVI8pfN7CmZmxUY6HafGNIpx1OH3FMzMCo00KUzav6ruUzAzK1bYpyDpERr/8RewZ2kRlazWxIkIpEnb4DEzK0VhUoiIfcYzkPHSkRJBRNbpbGZmu4z09tGk1ZESgd9qNjPbXfWSQsoK7lcwM9td5ZJCjVsKZma7q1xS6HBHgplZoQomheynWwpmZrurYFJwn4KZWZHKJQW5pWBmVqiCSWHXewpmZvZMlUsKtT4Fj39kZra7yiWF2rNH7lMwM9td5ZLCrpfXnBXMzOqVmhQkLZS0WVKfpOUNtp8laZOkGyT9WNLhZcaTjgm4T8HMrJHSkoKkTmAlcDKwADhV0oK6atcB3RHxIuAbwPllxVPPfQpmZrsrs6VwLNAXEVsi4mlgNbA4XyEiroyIx9Pq1cDsEuMBoO/uRwB45KntZR/KzGzSKTMpHArckVvvT2VFzgC+32iDpKWSeiX1DgwMjCqoFxyyHwDTOyvXnWJmNqQJ8ZdR0tuBbuCCRtsjYlVEdEdEd1dX16iO1emOZjOzQoWT7IyBrcCc3PrsVPYMkk4EPgb8p4h4qsR4gHxSKPtIZmaTT5kthXXAfEnzJE0HlgA9+QqSjgYuAhZFxD0lxpI7ZvZzh7OCmdluSksKEbEdWAasBW4CLo+IjZJWSFqUql0A7A18XdIGST0FuxsztZaCnz4yM9tdmbePiIg1wJq6snNyyyeWefxGaqOk7nBSMDPbzYToaB5Pg0Nn72xzIGZmE1AFk0L2008fmZntrnJJwY+kmpkVq1xSGOxT8NNHZma7qV5S8HsKZmaFqpcU3KdgZlaockmhc/DpIycFM7N6lUsK8nsKZmaFKpcUds3R3N44zMwmosolBT+SamZWrHJJQX4k1cysUOWSwq4B8dociJnZBFS5pNDhobPNzApVMCm4T8HMrIiTgpmZDapcUvB0nGZmxUpNCpIWStosqU/S8gbbXynpWknbJZ1SZiw17lMwMytWWlKQ1AmsBE4GFgCnSlpQV+124HTg0rLiqNfh9xTMzAqVOR3nsUBfRGwBkLQaWAxsqlWIiFvTtnGbB819CmZmxcq8fXQocEduvT+VDZukpZJ6JfUODAyMKqhOT8dpZlZoUnQ0R8SqiOiOiO6urq5R7Uu1PgW3FMzMdlNmUtgKzMmtz05lbVXrUxh45Kk2R2JmNvGUmRTWAfMlzZM0HVgC9JR4vJbcdt9jAFywdnObIzEzm3hKSwoRsR1YBqwFbgIuj4iNklZIWgQg6aWS+oE3ARdJ2lhWPDUz9+gs+xBmZpNWmU8fERFrgDV1ZefklteR3VYaN/vO3GM8D2dmNqlMio7msbTvzFLzoJnZpFa9pLCnWwpmZkUqlxRmTKvcKZuZtaxyfyFrM6+ZmdnuKpcUzMysWCV7XWftPZ2TFhzU7jDMzCacSrYUZu7RyVPbdrQ7DDOzCaeySeHJ7U4KZmb1KpoUOnjiaScFM7N6lUwKe8+YxqNPbW93GGZmE04lk8K+M/fgkSedFMzM6lUyKey35x48+Pi2dodhZjbhVDIp7Dm9kz8+/CThiXbMzJ6hkknhyfQ46t0Pe6IdM7O8SiaFxUdlU0Vf3/9gewMxM5tgKpkUjjxoHwB+fstAmyMxM5tYSk0KkhZK2iypT9LyBttnSLosbb9G0twy46mZtfcM5h74LL569e3c8/CT43FIM7NJobSkIKkTWAmcDCwATpW0oK7aGcADEfEnwD8CnywrnnoXvuUoAF79qZ/yocs28J3rttJ76/303fModz74BPc/9jSPP72dHTvDHdJmVhllDoh3LNAXEVsAJK0GFgObcnUWA+em5W8An5OkGIe/wsccdgA9y17BV6++jbUb7+bb121tWr+zQ3RK2c8O0aFsGO7aT5F+CmqDc9dG6VYqyY/avavOM4fyHvxO3XdHY7SjhY82gtEOVz4mg523+d/APGz9WDjz1fP5ixcfUuoxykwKhwJ35Nb7gZcV1YmI7ZIeAg4E7s1XkrQUWApw2GGHjVmAL5q9P+efsj//+7/uZMvAY9z10BM89MQ2nnh6B09u28GT23fy1Lad7Ihgx86d7NgJOyPYviPYGVkLIiAtQ2TnQXY+PPMnu/LcrrKCOnXbR2O0+XW0MYw2vU+FfwPD/4hjZL9xmDlyUgydHRGrgFUA3d3dY/7rtUdnB0cetM9gB7SZWVWV2dG8FZiTW5+dyhrWkTQN2A+4r8SYzMysiTKTwjpgvqR5kqYDS4Ceujo9wGlp+RTgJ+PRn2BmZo2Vdvso9REsA9YCncDFEbFR0gqgNyJ6gC8CX5HUB9xPljjMzKxNSu1TiIg1wJq6snNyy08CbyozBjMza10l32g2M7PGnBTMzGyQk4KZmQ1yUjAzs0GabE+AShoAbhvh12dR97Z0Bficq8HnXA2jOefDI6JrqEqTLimMhqTeiOhudxzjyedcDT7nahiPc/btIzMzG+SkYGZmg6qWFFa1O4A28DlXg8+5Gko/50r1KZiZWXNVaymYmVkTTgpmZjaoMklB0kJJmyX1SVre7niGQ9IcSVdK2iRpo6QzU/mzJf1Q0i3p5wGpXJI+m871BknH5PZ1Wqp/i6TTcuUvkXRj+s5nNUHmTpTUKek6SVek9XmSrklxXpaGZUfSjLTel7bPze3j7FS+WdJrc+UT7ndC0v6SviHpd5JukvTyqX6dJX0o/V7/VtLXJM2catdZ0sWS7pH021xZ6de16BhNRW1aySn8IRu6+/fAEcB04HpgQbvjGkb8BwPHpOV9gJuBBcD5wPJUvhz4ZFp+HfB9sqmFjwOuSeXPBraknwek5QPStt+kukrfPbnd553iOgu4FLgirV8OLEnLXwDel5b/GvhCWl4CXJaWF6TrPQOYl34POifq7wTwr8B70vJ0YP+pfJ3JpuT9A7Bn7vqePtWuM/BK4Bjgt7my0q9r0TGaxtru/wjG6YK8HFibWz8bOLvdcY3ifP4NOAnYDBycyg4GNqfli4BTc/U3p+2nAhflyi9KZQcDv8uVP6NeG89zNvBj4FXAFekX/l5gWv11JZu34+VpeVqqp/prXas3EX8nyGYe/APpAZD66zcVrzO75ml/drpuVwCvnYrXGZjLM5NC6de16BjNPlW5fVT7xavpT2WTTmouHw1cAzw3Iu5Km/4IPDctF51vs/L+BuXt9mngo8DOtH4g8GBEbE/r+TgHzy1tfyjVH+6/RTvNAwaAL6VbZv8iaS+m8HWOiK3APwC3A3eRXbf1TO3rXDMe17XoGIWqkhSmBEl7A98EPhgRD+e3Rfa/AlPm+WJJrwfuiYj17Y5lHE0ju8XwfyPiaOAxsib/oCl4nQ8AFpMlxEOAvYCFbQ2qDcbjurZ6jKokha3AnNz67FQ2aUjagywhXBIR30rFd0s6OG0/GLgnlRedb7Py2Q3K2+kVwCJJtwKryW4hfQbYX1JtxsB8nIPnlrbvB9zH8P8t2qkf6I+Ia9L6N8iSxFS+zicCf4iIgYjYBnyL7NpP5etcMx7XtegYhaqSFNYB89MTDdPJOqh62hxTy9KTBF8EboqIC3ObeoDaEwinkfU11MrfmZ5iOA54KDUh1wKvkXRA+j+015Ddb70LeFjScelY78ztqy0i4uyImB0Rc8mu108i4m3AlcApqVr9Odf+LU5J9SOVL0lPrcwD5pN1yk2434mI+CNwh6QjU9GrgU1M4etMdtvoOEnPSjHVznnKXuec8biuRcco1s5OpnHu5Hkd2VM7vwc+1u54hhn78WTNvhuADenzOrJ7qT8GbgF+BDw71RewMp3rjUB3bl/vBvrS51258m7gt+k7n6Ous7PN538Cu54+OoLsP/Y+4OvAjFQ+M633pe1H5L7/sXRem8k9bTMRfyeAo4DedK2/Q/aUyZS+zsB5wO9SXF8he4JoSl1n4GtkfSbbyFqEZ4zHdS06RrOPh7kwM7NBVbl9ZGZmLXBSMDOzQU4KZmY2yEnBzMwGOSmYmdkgJwWrLEm/Sj/nSnrrGO/77xody2yi8yOpVnmSTgA+EhGvH8Z3psWusXkabX80IvYeg/DMxpVbClZZkh5Ni58A/qOkDcrG9u+UdIGkdWk8+/+W6p8g6eeSesjeukXSdyStVzYfwNJU9glgz7S/S/LHSm+pXqBs7oAbJb0lt++rtGsuhUtqY+KbjadpQ1cxm/KWk2sppD/uD0XESyXNAH4p6Qep7jHACyPiD2n93RFxv6Q9gXWSvhkRyyUti4ijGhzrL8neWn4xMCt952dp29HAC4A7gV+SjQH0i7E+WbNm3FIw291ryMae2UA2RPmBZGPpAPwmlxAAPiDpeuBqssHK5tPc8cDXImJHRNwN/BR4aW7f/RGxk2wok7ljcC5mw+KWgtnuBLw/ItY+ozDre3isbv1EsklfHpd0FdnYPCP1VG55B/7v09rALQUzeIRsmtOatcD70nDlSHp+muym3n7AAykh/CnZdIg122rfr/Nz4C2p36KLbJrG34zJWZiNAf+fiFk2IumOdBvoy2TzNswFrk2dvQPAGxp87/8D75V0E9nInFfntq0CbpB0bWRDftd8m2yKyOvJRr79aET8MSUVs7bzI6lmZjbIt4/MzGyQk4KZmQ1yUjAzs0FOCmZmNshJwczMBjkpmJnZICcFMzMb9O9b9SMYsJV1MwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00029-1de44bc6-5f35-4df3-af9a-408291ccc867",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 174
        },
        "deepnote_cell_type": "markdown",
        "id": "4PcNxrCt-NcN"
      },
      "source": [
        "## Problem 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00030-fdaced74-34ab-4cfc-8fa2-f3a0b012fbf2",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 180
        },
        "deepnote_cell_type": "code",
        "id": "6Brepirl-Nln"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "class SmallNet6:\n",
        "    def __init__(self, in_features, number_of_hidden_layers, num_hidden, dtype=np.float32):\n",
        "        self.n_hidden_l = number_of_hidden_layers\n",
        "        self.size_hidden = num_hidden\n",
        "        self.W0 = np.zeros((num_hidden, in_features))\n",
        "        #hidden layers\n",
        "        self.W1 = np.zeros((number_of_hidden_layers-1, num_hidden, num_hidden), dtype=dtype)\n",
        "        self.b1 = np.zeros((number_of_hidden_layers, num_hidden), dtype=dtype)\n",
        "        # output layer \n",
        "        self.W2 = np.zeros((1, num_hidden), dtype=dtype)\n",
        "        self.b2 = np.zeros((1,), dtype=dtype)\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        self.W0 = np.random.normal(0, 0.5, self.W0.shape)\n",
        "        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n",
        "        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n",
        "        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n",
        "        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def forward(self, X, Y=None, do_backward=False):\n",
        "        \n",
        "        A1 = np.zeros((self.n_hidden_l, X.shape[0], self.size_hidden))\n",
        "        O1 = np.zeros((self.n_hidden_l, X.shape[0], self.size_hidden))\n",
        "        \n",
        "        # Calculating first hidden layer\n",
        "        A1[0] = X@self.W0.T+self.b1[0] # X x n\n",
        "        #O1[0] = sigmoid(A1[0])  # X x n\n",
        "        O1[0] = np.maximum(A1[0], 0)\n",
        "\n",
        "        # Calculating rest of hidden layers\n",
        "        for i in range(1, self.n_hidden_l):\n",
        "            A1[i] = O1[i-1]@self.W1[i-1].T+self.b1[i] # X x n\n",
        "            #O1[i] = sigmoid(A1[i]) # X x n\n",
        "            O1[i] = np.maximum(A1[i], 0)\n",
        "\n",
        "        #A1 = X@self.W1.T+self.b1\n",
        "        \n",
        "        #O1 = sigmoid(A1)\n",
        "        \n",
        "        # Calculating output layer\n",
        "        A2 = O1[-1]@self.W2.T+self.b2 # X x 1        \n",
        "        O2 = sigmoid(A2)  # X x 1\n",
        "\n",
        "        \n",
        "        if Y is not None:\n",
        "            loss = Y*np.log(O2) + (1-Y)*np.log(1 - O2)\n",
        "            # normalize loss by batch size\n",
        "            loss = - loss.sum() / X.shape[0]\n",
        "        else:\n",
        "            loss = np.nan\n",
        "\n",
        "        if do_backward:\n",
        "            # Calculating gradient for output layer\n",
        "            O2_grad = (O2-Y)/(O2-np.square(O2)) # X x 1\n",
        "            A2_grad = O2_grad*(sigmoid(A2)*(1 - sigmoid(A2))) # X x 1\n",
        "            self.b2_grad = A2_grad.sum(0)/X.shape[0]\n",
        "            self.W2_grad = np.array([(O1[-1]*A2_grad).sum(0)/X.shape[0]])\n",
        "            \n",
        "            # Init grad tables\n",
        "            A1_grad = np.zeros((self.n_hidden_l, X.shape[0], self.size_hidden))\n",
        "            O1_grad = np.zeros((self.n_hidden_l, X.shape[0], self.size_hidden))\n",
        "            self.W1_grad = np.zeros(self.W1.shape)\n",
        "            self.b1_grad = np.zeros(self.b1.shape)\n",
        "\n",
        "            O1_grad[-1] = self.W2*A2_grad\n",
        "            #For sigmoid function\n",
        "            #A1_grad[-1] = O1_grad[-1]*(sigmoid(A1[-1])*(1 - sigmoid(A1[-1])))\n",
        "            \n",
        "            #For ReLu function\n",
        "            A1_grad[-1] = O1_grad[-1]*(A1[-1] > 0).astype(int)\n",
        "            \n",
        "            # Calculating whole O1_grad and A1_grad to calculate b_grad and W_grad in next loop\n",
        "            # ----------------------------------------------------------------------------------\n",
        "            for i in range(1, self.n_hidden_l):\n",
        "                for j in range(self.size_hidden):\n",
        "                    O1_grad[self.n_hidden_l-1-i] += A1_grad[self.n_hidden_l-i][:, j][:, np.newaxis]@self.W1[self.n_hidden_l-1-i][j].reshape(1,self.W1.shape[1])\n",
        "                \n",
        "                #For sigmoid function\n",
        "                #A1_grad[self.n_hidden_l-1-i] = O1_grad[self.n_hidden_l-1-i]*(sigmoid(A1[self.n_hidden_l-1-i]) * (1 - sigmoid(A1[self.n_hidden_l-1-i])))\n",
        "\n",
        "                #For ReLu function\n",
        "                A1_grad[self.n_hidden_l-1-i] = O1_grad[self.n_hidden_l-1-i]*(A1[self.n_hidden_l-1-i] > 0).astype(int)\n",
        "\n",
        "\n",
        "            # print(O1_grad[0])\n",
        "            # print(A1_grad[0])\n",
        "\n",
        "            # Calculating W1_grad and b1_grad\n",
        "            \n",
        "            for i in range(self.W1.shape[0]):\n",
        "                for j in range(X.shape[0]):\n",
        "                    self.W1_grad[i] += (O1[i][j][:, np.newaxis]*A1_grad[i+1][j]).T \n",
        "            \n",
        "            self.W1_grad /= X.shape[0]\n",
        "            for i in range(self.b1.shape[0]):\n",
        "                self.b1_grad[i] = A1_grad[i].sum(0)/X.shape[0] \n",
        "              \n",
        "            \n",
        "\n",
        "            self.W0_grad = np.zeros(self.W0.shape)\n",
        "            for i in range(X.shape[0]):\n",
        "                self.W0_grad += (X[i][:, np.newaxis]*A1_grad[0][i]).T\n",
        "            self.W0_grad /= X.shape[0]\n",
        "\n",
        "        return O2, loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SmallNet6(3, 4, 5, dtype=np.float64)\n",
        "\n",
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "# _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "result = np.zeros((100000,))\n",
        "\n",
        "\n",
        "for i in range(100000):\n",
        "    _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "    for param_name in [\"W0\", \"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "        param = getattr(net, param_name)\n",
        "        param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "    result[i] = loss\n",
        "\n",
        "plt.title(\"Loss function\")\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"Loss function\")\n",
        "plt.plot(np.arange(100000), result)\n",
        "\n",
        "print(f'Last loss value: {result[99999]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "ksljwrK0gwZI",
        "outputId": "3f451ce2-dfa3-434d-b436-75c712bf4531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last loss value: 2.071008353885128e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([1, 2, 3, 5, 10])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in tqdm(range(len(array))):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet6(3, array[hidden_dim], 2, dtype=np.float64)\n",
        "        for i in range(10000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W0\", \"b1\", \"W1\", \"b2\", \"W2\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 10k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "rne-zuX7IiZw",
        "outputId": "e44c9ec8-8a54-435e-c007-3e9921a15eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [37:46<00:00, 453.30s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([1, 2, 3, 5, 10])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in tqdm(range(len(array))):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet6(3, array[hidden_dim], 3, dtype=np.float64)\n",
        "        for i in range(10000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W0\", \"b1\", \"W1\", \"b2\", \"W2\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 10k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "fXve_OZ_YNTm",
        "outputId": "d3ee528e-5ecc-4c74-924b-2cdf1b3de493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [39:34<00:00, 474.93s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([1, 2, 3, 5, 10])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in tqdm(range(len(array))):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet6(3, array[hidden_dim], 5, dtype=np.float64)\n",
        "        for i in range(10000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W0\", \"b1\", \"W1\", \"b2\", \"W2\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 10k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "wMf1N-mwEKX9",
        "outputId": "1cf5033f-3c4a-4d1c-9ce7-49d2792d8a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [44:11<00:00, 530.34s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1  # set a learning rate\n",
        "\n",
        "array = np.array([1, 2, 3, 5, 10])\n",
        "result = np.zeros((5,))\n",
        "\n",
        "for hidden_dim in tqdm(range(len(array))):\n",
        "    for iter in range(100):\n",
        "        net = SmallNet6(3, array[hidden_dim], 10, dtype=np.float64)\n",
        "        for i in range(10000):\n",
        "            _, loss = net.forward(X3, Y3, do_backward=True)\n",
        "            # if (i % 5000) == 0:\n",
        "            #     print(f\"after {i} steps \\tloss={loss}\")\n",
        "            for param_name in [\"W0\", \"b1\", \"W1\", \"b2\", \"W2\"]:\n",
        "                param = getattr(net, param_name)\n",
        "                # Hint: use the construct `param[:]` to change the contents of the array!\n",
        "                # Doing instead `param = new_val` simply changes to what the variable\n",
        "                # param points to, without affecting the network!\n",
        "                # alternatively, you could do setattr(net, param_name, new_value)\n",
        "                param[:] = param[:] - alpha*getattr(net, param_name + '_grad')\n",
        "        result[hidden_dim] += loss\n",
        "\n",
        "plt.title('Avg loss after 10k iterations')\n",
        "plt.bar(array.astype(str), result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "jZI6Zvi5IbCD",
        "outputId": "7e9fe4e8-d55c-41b0-eca5-75c64ace3ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [29:49<08:54, 534.96s/it]<ipython-input-18-b6762fd23db5>:53: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = Y*np.log(O2) + (1-Y)*np.log(1 - O2)\n",
            "<ipython-input-18-b6762fd23db5>:53: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = Y*np.log(O2) + (1-Y)*np.log(1 - O2)\n",
            "<ipython-input-18-b6762fd23db5>:61: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  O2_grad = (O2-Y)/(O2-np.square(O2)) # X x 1\n",
            "<ipython-input-18-b6762fd23db5>:61: RuntimeWarning: invalid value encountered in true_divide\n",
            "  O2_grad = (O2-Y)/(O2-np.square(O2)) # X x 1\n",
            "<ipython-input-18-b6762fd23db5>:62: RuntimeWarning: invalid value encountered in multiply\n",
            "  A2_grad = O2_grad*(sigmoid(A2)*(1 - sigmoid(A2))) # X x 1\n",
            "100%|██████████| 5/5 [55:00<00:00, 660.08s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00031-032edb86-1c56-46e7-8ea3-3e011d72bf5f",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 186
        },
        "deepnote_cell_type": "markdown",
        "id": "nWuv7Q77-Nut"
      },
      "source": [
        "## Problem 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00032-2eab2b1a-f83b-409c-a066-1642cd2ab2d8",
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 12,
          "x": 0,
          "y": 192
        },
        "deepnote_cell_type": "code",
        "id": "avuvSoWY-N4Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "deepnote": {},
    "deepnote_app_layout": "article",
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "1f038069-bae5-44e5-92ba-67bdff2c54a6",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}